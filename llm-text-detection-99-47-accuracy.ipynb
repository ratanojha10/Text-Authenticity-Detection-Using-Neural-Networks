{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7378735,"sourceType":"datasetVersion","datasetId":4287904}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detection of Large-Language Model (LLM) Generated Text\n\n[![GitHub](https://img.icons8.com/material-outlined/24/000000/github.png)](https://github.com/Harshithvarma007/LLM_Text_Detection)\n[![Medium](https://img.icons8.com/ios-filled/24/000000/medium-monogram.png)](https://medium.com/@harshith007varma007/end-to-end-machine-learning-project-part-i-c29c2b982055)\n\n## Introduction\nIn this notebook, we explore the task of detecting text generated by LLM models. LLM models, known for their rapid generation of high-quality text, have gained popularity in various applications such as chatbots, content generation, and automated writing. However, with the rise of LLM-generated content, there is a growing need to distinguish between human-generated and LLM-generated text due to concerns related to misinformation, plagiarism, and ethics.\n\n## Need for Detection of LLM Generated Text\nThe need for detecting LLM-generated text arises from several factors:\n- **Misinformation Control:** LLMs can be used to spread false information rapidly. Detection helps in identifying and mitigating the impact of misinformation.\n- **Plagiarism Prevention:** Identifying LLM-generated content assists in preventing academic and content plagiarism, maintaining integrity in research and publications.\n- **Ethical Considerations:** Understanding the origin of text content is crucial for maintaining ethical standards, especially in sensitive areas like news reporting and legal documentation.\n- **Trust and Transparency:** Detection fosters trust by ensuring transparency about the source of text content, enhancing credibility in communication channels.\n\n## Summary\nIn this notebook, we address the challenge of detecting LLM-generated text by leveraging natural language processing (NLP) techniques. We explore feature engineering, model selection, and evaluation metrics to build an effective detection system. The goal is to contribute to the development of tools and methodologies for maintaining the integrity and reliability of text-based communication in the era of rapid text generation technologies.\n\n## Conclusion\nIn conclusion, the detection of LLM-generated text is a critical task in today's digital landscape. By developing robust detection mechanisms, we can mitigate the risks associated with misinformation, plagiarism, and ethical concerns. This notebook serves as a starting point for further research and application of NLP techniques in text authenticity verification.\n\n---\n\n### Project Deployment\nThe project has been deployed [here](http://54.196.76.117:8501/).\n","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom wordcloud import WordCloud\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:24.558567Z","iopub.execute_input":"2024-06-22T05:14:24.558985Z","iopub.status.idle":"2024-06-22T05:14:42.428378Z","shell.execute_reply.started":"2024-06-22T05:14:24.558951Z","shell.execute_reply":"2024-06-22T05:14:42.426495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Datasets","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')\ntrain_1=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:42.431010Z","iopub.execute_input":"2024-06-22T05:14:42.431943Z","iopub.status.idle":"2024-06-22T05:14:45.064133Z","shell.execute_reply.started":"2024-06-22T05:14:42.431900Z","shell.execute_reply":"2024-06-22T05:14:45.062720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explroing Datstets","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:45.066802Z","iopub.execute_input":"2024-06-22T05:14:45.067390Z","iopub.status.idle":"2024-06-22T05:14:45.101378Z","shell.execute_reply.started":"2024-06-22T05:14:45.067341Z","shell.execute_reply":"2024-06-22T05:14:45.099798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:45.104081Z","iopub.execute_input":"2024-06-22T05:14:45.104915Z","iopub.status.idle":"2024-06-22T05:14:45.123579Z","shell.execute_reply.started":"2024-06-22T05:14:45.104877Z","shell.execute_reply":"2024-06-22T05:14:45.121925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution","metadata":{}},{"cell_type":"code","source":"# Plot for train dataset\nplt.figure(figsize=(8, 6))\ntrain['label'].value_counts().plot(kind='bar', color=['blue', 'green'])\nplt.title('Distribution of \"generated\" in train dataset')\nplt.xlabel('Generated')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:45.126270Z","iopub.execute_input":"2024-06-22T05:14:45.126760Z","iopub.status.idle":"2024-06-22T05:14:45.513835Z","shell.execute_reply.started":"2024-06-22T05:14:45.126722Z","shell.execute_reply":"2024-06-22T05:14:45.512288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot for train_1 dataset\nplt.figure(figsize=(8, 6))\ntrain_1['generated'].value_counts().plot(kind='bar', color=['blue', 'green'])\nplt.title('Distribution of \"generated\" in train_1 dataset')\nplt.xlabel('Generated')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:45.515556Z","iopub.execute_input":"2024-06-22T05:14:45.516014Z","iopub.status.idle":"2024-06-22T05:14:45.770907Z","shell.execute_reply.started":"2024-06-22T05:14:45.515969Z","shell.execute_reply":"2024-06-22T05:14:45.769268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine Datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Selecting necessary columns from train dataset\ntrain_selected = train[['text', 'label']].copy()\n\n# Selecting necessary columns from train_1 dataset and renaming 'generated' to match the 'label' column\ntrain_1_selected = train_1[['text', 'generated']].rename(columns={'generated': 'label'}).copy()\n\n# Concatenating the selected columns from both datasets\ncombined_data = pd.concat([train_selected, train_1_selected], ignore_index=True)\n\n# Displaying the combined data\nprint(combined_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:45.773045Z","iopub.execute_input":"2024-06-22T05:14:45.773540Z","iopub.status.idle":"2024-06-22T05:14:45.808056Z","shell.execute_reply.started":"2024-06-22T05:14:45.773493Z","shell.execute_reply":"2024-06-22T05:14:45.806281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_data.columns","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:30:30.834883Z","iopub.execute_input":"2024-06-22T05:30:30.836311Z","iopub.status.idle":"2024-06-22T05:30:30.844967Z","shell.execute_reply.started":"2024-06-22T05:30:30.836261Z","shell.execute_reply":"2024-06-22T05:30:30.843322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Calculate class distribution\nclass_distribution = combined_data['label'].value_counts()\n\n# Plotting the class distribution\nplt.figure(figsize=(6, 6))\nplt.pie(class_distribution, labels=class_distribution.index, autopct='%1.1f%%', colors=['lightblue', 'lightgreen'])\nplt.title('Class Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:10.800805Z","iopub.status.idle":"2024-06-22T05:14:10.801256Z","shell.execute_reply.started":"2024-06-22T05:14:10.801019Z","shell.execute_reply":"2024-06-22T05:14:10.801035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for duplicates in combined_data\nduplicate_rows = combined_data[combined_data.duplicated()]\nprint(\"Duplicate Rows:\")\nprint(duplicate_rows)\n\n\n# Checking for null values in combined_data\nnull_values = combined_data.isnull().sum()\nprint(\"\\nNull Values:\")\nprint(null_values)\n\n# Dropping duplicates and null values from combined_data\ncombined_data.drop_duplicates(inplace=True)\ncombined_data.dropna(inplace=True)\n\n# Confirming the removal of duplicates and null values\nprint(\"\\nAfter Dropping:\")\nprint(combined_data.shape)  # Check the shape after dropping\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:10.802681Z","iopub.status.idle":"2024-06-22T05:14:10.803117Z","shell.execute_reply.started":"2024-06-22T05:14:10.802920Z","shell.execute_reply":"2024-06-22T05:14:10.802938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Calculate class distribution\nclass_distribution = combined_data['label'].value_counts()\n\n# Plotting the class distribution\nplt.figure(figsize=(6, 6))\nplt.pie(class_distribution, labels=class_distribution.index, autopct='%1.1f%%', colors=['lightblue', 'lightgreen'])\nplt.title('Class Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:10.804694Z","iopub.status.idle":"2024-06-22T05:14:10.805107Z","shell.execute_reply.started":"2024-06-22T05:14:10.804912Z","shell.execute_reply":"2024-06-22T05:14:10.804930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Cloud ","metadata":{}},{"cell_type":"code","source":"\n\n# Filter the combined data based on label values\nlabel_0_text = ' '.join(combined_data[combined_data['label'] == 0]['text'])\nlabel_1_text = ' '.join(combined_data[combined_data['label'] == 1]['text'])\n\n# Generate word clouds\nwordcloud_0 = WordCloud(width=800, height=400, background_color='white').generate(label_0_text)\nwordcloud_1 = WordCloud(width=800, height=400, background_color='white').generate(label_1_text)\n\n\n# Plotting word cloud for label=0\nplt.figure(figsize=(8, 6))\nplt.imshow(wordcloud_0, interpolation='bilinear')\nplt.title('Word Cloud for label=0')\nplt.axis('off')\nplt.show()\n\n# Plotting word cloud for label=1\nplt.figure(figsize=(8, 6))\nplt.imshow(wordcloud_1, interpolation='bilinear')\nplt.title('Word Cloud for label=1')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T05:14:10.806810Z","iopub.status.idle":"2024-06-22T05:14:10.807200Z","shell.execute_reply.started":"2024-06-22T05:14:10.807010Z","shell.execute_reply":"2024-06-22T05:14:10.807028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize the TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n\n# Tokenize and create TF-IDF vectors for the 'text' column of the combined dataset\ntfidf_vectors = tfidf_vectorizer.fit_transform(combined_data['text'])\n\n# Convert TF-IDF vectors to a DataFrame for easy analysis\ntfidf_df = pd.DataFrame(tfidf_vectors.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Display the TF-IDF DataFrame\nprint(tfidf_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:13:53.889800Z","iopub.execute_input":"2024-06-21T12:13:53.890281Z","iopub.status.idle":"2024-06-21T12:14:10.277573Z","shell.execute_reply.started":"2024-06-21T12:13:53.890238Z","shell.execute_reply":"2024-06-21T12:14:10.276255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting The Dataset (80-20)","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX = tfidf_df.values  # Features (TF-IDF vectors)\ny = combined_data['label'].values  # Target variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:14:10.280122Z","iopub.execute_input":"2024-06-21T12:14:10.280558Z","iopub.status.idle":"2024-06-21T12:14:11.134702Z","shell.execute_reply.started":"2024-06-21T12:14:10.280518Z","shell.execute_reply":"2024-06-21T12:14:11.133656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoder","metadata":{}},{"cell_type":"code","source":"\n# Encode target labels (0 and 1) using LabelEncoder\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:14:11.135970Z","iopub.execute_input":"2024-06-21T12:14:11.136291Z","iopub.status.idle":"2024-06-21T12:14:11.143982Z","shell.execute_reply.started":"2024-06-21T12:14:11.136264Z","shell.execute_reply":"2024-06-21T12:14:11.142803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Neuarl Network for Text Classification","metadata":{}},{"cell_type":"code","source":"# Build a simple neural network model\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:14:38.074277Z","iopub.execute_input":"2024-06-21T12:14:38.074690Z","iopub.status.idle":"2024-06-21T12:14:38.137498Z","shell.execute_reply.started":"2024-06-21T12:14:38.074655Z","shell.execute_reply":"2024-06-21T12:14:38.136212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training The Model","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test, y_test_encoded), verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:14:52.889873Z","iopub.execute_input":"2024-06-21T12:14:52.890972Z","iopub.status.idle":"2024-06-21T12:16:13.485570Z","shell.execute_reply.started":"2024-06-21T12:14:52.890913Z","shell.execute_reply":"2024-06-21T12:16:13.484302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Model","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\nprint(f'Test Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:16:39.509691Z","iopub.execute_input":"2024-06-21T12:16:39.510113Z","iopub.status.idle":"2024-06-21T12:16:40.593914Z","shell.execute_reply.started":"2024-06-21T12:16:39.510081Z","shell.execute_reply":"2024-06-21T12:16:40.592681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score\n\n# Predict probabilities for the test set\ny_pred_prob = model.predict(X_test)\n\n# Convert probabilities to binary predictions (0 or 1)\ny_pred = (y_pred_prob > 0.5).astype(int)\n\n# Calculate and print classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test_encoded, y_pred))\n\n# Calculate ROC-AUC score\nroc_auc = roc_auc_score(y_test_encoded, y_pred_prob)\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:17:03.323494Z","iopub.execute_input":"2024-06-21T12:17:03.324538Z","iopub.status.idle":"2024-06-21T12:17:04.459130Z","shell.execute_reply.started":"2024-06-21T12:17:03.324497Z","shell.execute_reply":"2024-06-21T12:17:04.457955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\n\n# Calculate classification report\nreport = classification_report(y_test_encoded, y_pred, output_dict=True)\nreport_df = pd.DataFrame(report).transpose()\n\n# Plotting the classification report as a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(report_df.iloc[:-1, :].astype(float), annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Classification Report')\nplt.xlabel('Metrics')\nplt.ylabel('Classes')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:17:04.528701Z","iopub.execute_input":"2024-06-21T12:17:04.529143Z","iopub.status.idle":"2024-06-21T12:17:04.901470Z","shell.execute_reply.started":"2024-06-21T12:17:04.529108Z","shell.execute_reply":"2024-06-21T12:17:04.900131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Calculate the confusion matrix\nconf_matrix = confusion_matrix(y_test_encoded, y_pred)\n\n# Plotting the confusion matrix as a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:17:35.986677Z","iopub.execute_input":"2024-06-21T12:17:35.988078Z","iopub.status.idle":"2024-06-21T12:17:36.265533Z","shell.execute_reply.started":"2024-06-21T12:17:35.988021Z","shell.execute_reply":"2024-06-21T12:17:36.264285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Tokenizer and Model","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# Save the TF-IDF tokenizer\nwith open('tfidf_tokenizer.pkl', 'wb') as f:\n    pickle.dump(tfidf_vectorizer, f)\n\n# Save the trained model\nmodel.save('text_classification_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:24:07.358401Z","iopub.execute_input":"2024-06-21T12:24:07.358888Z","iopub.status.idle":"2024-06-21T12:24:07.450867Z","shell.execute_reply.started":"2024-06-21T12:24:07.358852Z","shell.execute_reply":"2024-06-21T12:24:07.449692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Usage Code","metadata":{}},{"cell_type":"code","source":"# import pickle\n# from tensorflow.keras.models import load_model\n\n# # Load the TF-IDF tokenizer\n# with open('tfidf_tokenizer.pkl', 'rb') as f:\n#     tfidf_tokenizer = pickle.load(f)\n\n# # Load the trained model\n# loaded_model = load_model('text_classification_model.h5')\n\n# # Function to preprocess text and make predictions\n# def predict_outcome(text):\n#     # Preprocess the text using the loaded tokenizer\n#     text_features = tfidf_tokenizer.transform([text])\n    \n#     # Make predictions using the loaded model\n#     predictions = loaded_model.predict(text_features)\n    \n#     # Return the predicted outcome (1 for positive, 0 for negative)\n#     return int(predictions[0][0])\n\n# # Example usage\n# input_text = \"\"\"\n# Title: The Impact of Artificial Intelligence on Society\n\n# In recent years, the rapid advancements in artificial intelligence (AI) have sparked both excitement and concern across various sectors of society. AI, a branch of computer science that aims to create intelligent machines capable of learning and performing tasks that typically require human intelligence, has the potential to revolutionize industries, improve efficiency, and enhance our daily lives. However, its widespread adoption also raises ethical, social, and economic challenges that must be addressed.\n\n# One of the most significant impacts of AI is its role in automation. AI-powered systems and robots are increasingly being used in manufacturing, healthcare, transportation, and other sectors to streamline processes, increase productivity, and reduce human error. For example, in the healthcare industry, AI algorithms can analyze medical images, assist in diagnostics, and even predict patient outcomes, leading to faster and more accurate medical interventions.\n\n# Moreover, AI has enabled the development of virtual assistants and chatbots that provide personalized services and support to users. These AI-driven interfaces can answer queries, schedule appointments, recommend products, and perform various tasks, improving customer experiences and optimizing business operations.\n\n# However, as AI continues to evolve, concerns about job displacement and inequality have emerged. The automation of tasks previously performed by humans has led to discussions about the future of work and the need for reskilling and upskilling the workforce to adapt to the changing technological landscape. Additionally, the concentration of AI capabilities in the hands of a few tech giants raises questions about data privacy, algorithmic bias, and the ethical use of AI systems.\n\n# Furthermore, the ethical implications of AI in decision-making processes have become a topic of debate. AI algorithms trained on historical data may perpetuate biases and discrimination, leading to unfair outcomes in areas such as hiring, lending, and law enforcement. Addressing these biases and ensuring transparency and accountability in AI systems is crucial for building trust and promoting responsible AI deployment.\n\n# In conclusion, while AI offers tremendous potential for innovation and progress, it also poses significant challenges that require careful consideration and ethical governance. By fostering collaboration between stakeholders, investing in education and training, and adopting principles of fairness and transparency, we can harness the benefits of AI while mitigating its risks and ensuring a more inclusive and equitable future for society.\n# \"\"\"\n\n\n# predicted_label = predict_outcome(input_text)\n# print(\"Predicted Label:\", predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:28:19.241735Z","iopub.execute_input":"2024-06-21T12:28:19.242530Z","iopub.status.idle":"2024-06-21T12:28:19.606979Z","shell.execute_reply.started":"2024-06-21T12:28:19.242491Z","shell.execute_reply":"2024-06-21T12:28:19.605701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}